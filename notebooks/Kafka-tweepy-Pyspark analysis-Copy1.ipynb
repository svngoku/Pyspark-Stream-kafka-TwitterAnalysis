{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf34ae1",
   "metadata": {},
   "source": [
    "# Ingesting realtime tweets using Apache Kafka, Tweepy and Python\n",
    "\n",
    "## Purpose:\n",
    "\n",
    "Main data source for the lambda architecture pipeline\n",
    "uses twitter streaming API to simulate new events coming in every minute\n",
    "Kafka Producer sends the tweets as records to the Kafka Broker\n",
    "Contents:\n",
    "\n",
    "- Twitter setup\n",
    "- Defining the Kafka producer\n",
    "- Producing and sending records to the Kafka Broker\n",
    "- Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pyspark tweepy pymongo kafka-python \"pymongo[srv]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d7162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import StreamingClient, StreamRule\n",
    "from kafka import KafkaProducer\n",
    "from pyspark.sql import functions as f\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from kafka import KafkaProducer\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pymongo\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2084e8f",
   "metadata": {},
   "source": [
    "## Base de données SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2216af7",
   "metadata": {},
   "source": [
    "#  Configuration de Twitter \n",
    "\n",
    "getting the API object using authorization information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d210853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter setup\n",
    "consumer_key = \"886bWUB38AHD1VC8vE777rVKs\"\n",
    "consumer_secret = \"QLTWRcxbmxjOAAJatf4WCbL7j5vQYiyhSImv00wLarPVctcXE4\"\n",
    "access_token = \"765095367067262976-Nz1XFSRSQjdd2MKYdPLiyKpjTUSsEoo\"\n",
    "access_token_secret = \"8GZJcQVFJEk4SBrGgjk0V1HXiFau920Jt62Dntgf65qug\"\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAF0CeAEAAAAAep52nhowJZuk9B5RzizY8pJ7UfU%3Da5MK3zCKaEvktiqRgFrwwIt3gqkU53nNYWgnkl9bXbf2ygfscy\"\n",
    "# Creating the authentication object\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "# Creating the API object by passing in auth information\n",
    "api = tweepy.API(auth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c070c007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication Successful\n"
     ]
    }
   ],
   "source": [
    "#try connection\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Authentication Successful\")\n",
    "except:\n",
    "    print(\"Authentication Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21457f",
   "metadata": {},
   "source": [
    "# Création du producer Kafka \n",
    "\n",
    "- specify the Kafka Broker\n",
    "- specify the topic name\n",
    "- optional: specify partitioning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac7aad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_name = 'tweets_stream'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed455492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kafka_stream_tweets(data):\n",
    "    producer = KafkaProducer(\n",
    "        value_serializer=lambda m: json.dumps(m).encode('utf-8'),\n",
    "        bootstrap_servers='localhost:9092'\n",
    "    )\n",
    "    print(data)\n",
    "    producer.send(topic_name, value=data)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8257963c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream encountered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/svngoku/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tweepy/streaming.py\", line 91, in _connect\n",
      "    self.on_data(line)\n",
      "  File \"/var/folders/65/rsl7lrd91h178dgdgmq6ks9r0000gn/T/ipykernel_41767/874197983.py\", line 11, in on_data\n",
      "    kafka_stream_tweets(stream_messages)\n",
      "  File \"/var/folders/65/rsl7lrd91h178dgdgmq6ks9r0000gn/T/ipykernel_41767/1847031834.py\", line 4, in kafka_stream_tweets\n",
      "    bootstrap_servers='localhost:9092'\n",
      "  File \"/Users/svngoku/opt/anaconda3/envs/tf/lib/python3.7/site-packages/kafka/producer/kafka.py\", line 383, in __init__\n",
      "    **self.config)\n",
      "  File \"/Users/svngoku/opt/anaconda3/envs/tf/lib/python3.7/site-packages/kafka/client_async.py\", line 244, in __init__\n",
      "    self.config['api_version'] = self.check_version(timeout=check_timeout)\n",
      "  File \"/Users/svngoku/opt/anaconda3/envs/tf/lib/python3.7/site-packages/kafka/client_async.py\", line 900, in check_version\n",
      "    raise Errors.NoBrokersAvailable()\n",
      "kafka.errors.NoBrokersAvailable: NoBrokersAvailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing message \n",
      "{'tweet': {'created_at': '2022-06-27T17:53:38.000Z', 'id': '1541479885612482562', 'text': 'RT @humanite_fr: Procès #FranceTelecom « Le PDG était parfaitement informé des remontées et alertes émises »\\nLe parquet a requis des peines…'}, 'date_time': '2022-06-27 19:53:44'}\n",
      "Kafka messages: {'tweet': {'created_at': '2022-06-27T17:53:38.000Z', 'id': '1541479885612482562', 'text': 'RT @humanite_fr: Procès #FranceTelecom « Le PDG était parfaitement informé des remontées et alertes émises »\\nLe parquet a requis des peines…'}, 'date_time': '2022-06-27 19:53:44'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream encountered an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/svngoku/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tweepy/streaming.py\", line 91, in _connect\n",
      "    self.on_data(line)\n",
      "  File \"/var/folders/65/rsl7lrd91h178dgdgmq6ks9r0000gn/T/ipykernel_41767/874197983.py\", line 11, in on_data\n",
      "    kafka_stream_tweets(stream_messages)\n",
      "  File \"/var/folders/65/rsl7lrd91h178dgdgmq6ks9r0000gn/T/ipykernel_41767/1847031834.py\", line 4, in kafka_stream_tweets\n",
      "    bootstrap_servers='localhost:9092'\n",
      "  File \"/Users/svngoku/opt/anaconda3/envs/tf/lib/python3.7/site-packages/kafka/producer/kafka.py\", line 383, in __init__\n",
      "    **self.config)\n",
      "  File \"/Users/svngoku/opt/anaconda3/envs/tf/lib/python3.7/site-packages/kafka/client_async.py\", line 244, in __init__\n",
      "    self.config['api_version'] = self.check_version(timeout=check_timeout)\n",
      "  File \"/Users/svngoku/opt/anaconda3/envs/tf/lib/python3.7/site-packages/kafka/client_async.py\", line 900, in check_version\n",
      "    raise Errors.NoBrokersAvailable()\n",
      "kafka.errors.NoBrokersAvailable: NoBrokersAvailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing message \n",
      "{'tweet': {'id': '1541480340971261952', 'text': 'RT @humanite_fr: Procès #FranceTelecom « Le PDG était parfaitement informé des remontées et alertes émises »\\nLe parquet a requis des peines…'}, 'date_time': '2022-06-27 19:55:32'}\n",
      "Kafka messages: {'tweet': {'id': '1541480340971261952', 'text': 'RT @humanite_fr: Procès #FranceTelecom « Le PDG était parfaitement informé des remontées et alertes émises »\\nLe parquet a requis des peines…'}, 'date_time': '2022-06-27 19:55:32'}\n"
     ]
    }
   ],
   "source": [
    "class Streamer(StreamingClient):\n",
    "    def on_data(self, data):\n",
    "        json_data = json.loads(data)\n",
    "        stream_messages = {}\n",
    "        print(f\"Preparing message \")\n",
    "        event_time = datetime.now()\n",
    "        stream_messages[\"tweet\"] = json_data[\"data\"]\n",
    "        stream_messages[\"date_time\"] = event_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(stream_messages)\n",
    "        print(f\"Kafka messages: {stream_messages}\")\n",
    "        kafka_stream_tweets(stream_messages)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def on_connection_error(self):\n",
    "        self.disconnect()\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        print(status.id)\n",
    "\n",
    "\n",
    "KafkaPrinter = Streamer(bearer_token)\n",
    "rule = StreamRule(value=\"harcelement\")\n",
    "KafkaPrinter.add_rules(rule)\n",
    "KafkaPrinter.filter(tweet_fields=\"created_at\")\n",
    "KafkaPrinter.filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d4504e-9fa3-413f-a454-43cc80ec32b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
